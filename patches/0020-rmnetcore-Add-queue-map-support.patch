From c10133d3dd0a586fa52f6cceaeeafbde8a6ffe4c Mon Sep 17 00:00:00 2001
From: Subash Abhinov Kasiviswanathan <quic_subashab@quicinc.com>
Date: Tue, 17 Jan 2023 18:25:06 -0700
Subject: [PATCH 20/26] rmnetcore: Add queue map support

Adds support for binding flows to TX queues as well as enabling and
disabling them

Change-Id: Idd7b0a9cb73279b9579c1b91304c22a12376cbe1
Signed-off-by: Subash Abhinov Kasiviswanathan <quic_subashab@quicinc.com>
---
 .../ethernet/qualcomm/rmnet/rmnet_config.c    | 115 +++++++++++++++++-
 .../ethernet/qualcomm/rmnet/rmnet_config.h    |  15 +++
 .../net/ethernet/qualcomm/rmnet/rmnet_vnd.c   |  18 +++
 3 files changed, 145 insertions(+), 3 deletions(-)

diff --git a/drivers/net/ethernet/qualcomm/rmnet/rmnet_config.c b/drivers/net/ethernet/qualcomm/rmnet/rmnet_config.c
index 64b209a0ad21..d068b4a4ccf8 100644
--- a/drivers/net/ethernet/qualcomm/rmnet/rmnet_config.c
+++ b/drivers/net/ethernet/qualcomm/rmnet/rmnet_config.c
@@ -1,5 +1,6 @@
 // SPDX-License-Identifier: GPL-2.0-only
 /* Copyright (c) 2013-2018, The Linux Foundation. All rights reserved.
+ * Copyright (c) 2023, Qualcomm Innovation Center, Inc. All rights reserved.
  *
  * RMNET configuration engine
  */
@@ -8,6 +9,7 @@
 #include <linux/module.h>
 #include <linux/netlink.h>
 #include <linux/netdevice.h>
+#include <linux/xarray.h>
 #include "rmnet_config.h"
 #include "rmnet_handlers.h"
 #include "rmnet_vnd.h"
@@ -15,9 +17,15 @@
 
 /* Local Definitions and Declarations */
 
-static const struct nla_policy rmnet_policy[IFLA_RMNET_MAX + 1] = {
+enum {
+	IFLA_RMNET_QUEUE = __IFLA_RMNET_MAX,
+	__IFLA_RMNET_EXT_MAX,
+};
+
+static const struct nla_policy rmnet_policy[__IFLA_RMNET_EXT_MAX] = {
 	[IFLA_RMNET_MUX_ID]	= { .type = NLA_U16 },
 	[IFLA_RMNET_FLAGS]	= { .len = sizeof(struct ifla_rmnet_flags) },
+	[IFLA_RMNET_QUEUE]	= { .len = sizeof(struct rmnet_queue_mapping) },
 };
 
 static int rmnet_is_real_dev_registered(const struct net_device *real_dev)
@@ -83,6 +91,83 @@ static int rmnet_register_real_device(struct net_device *real_dev,
 	return 0;
 }
 
+static void rmnet_update_queue_map(struct net_device *dev, u8 operation,
+				     u8 txqueue, u32 mark)
+{
+	struct rmnet_priv *priv = netdev_priv(dev);
+	struct netdev_queue *q;
+	u8 *txq;
+
+	switch (operation) {
+	case RMNET_QUEUE_MAPPING_ADD:
+		xa_store(&priv->queue_map, mark, &txqueue, GFP_ATOMIC);
+		txq = xa_load(&priv->queue_map, mark);
+		if (txq)
+			netdev_dbg(dev, "%s(): mark %08x -> txq %02x\n",
+				   __func__, mark, *txq);
+		else
+			netdev_dbg(dev, "%s(): No mapping for mark %08x\n",
+				   __func__, mark);
+
+		break;
+	case RMNET_QUEUE_MAPPING_REMOVE:
+		xa_erase(&priv->queue_map, mark);
+		txq = xa_load(&priv->queue_map, mark);
+		if (txq)
+			netdev_dbg(dev, "%s(): mark %08x -> txq %02x\n",
+				   __func__, mark, *txq);
+		else
+			netdev_dbg(dev, "%s(): No mapping for mark %08x\n",
+				   __func__, mark);
+
+		break;
+	case RMNET_QUEUE_ENABLE:
+		txq = xa_load(&priv->queue_map, mark);
+		if (txq) {
+			netdev_dbg(dev,
+				   "%s(): mark %08x -> txq %02x [ENABLE]\n",
+				   __func__, mark, *txq);
+		} else {
+			netdev_dbg(dev, "%s(): No mapping for mark %08x\n",
+				   __func__, mark);
+			break;
+		}
+
+		if (unlikely(*txq >= dev->num_tx_queues))
+			break;
+
+		q = netdev_get_tx_queue(dev, *txq);
+		if (unlikely(!q))
+			break;
+
+		netif_tx_wake_queue(q);
+		break;
+	case RMNET_QUEUE_DISABLE:
+		txq = xa_load(&priv->queue_map, mark);
+		if (txq) {
+			netdev_dbg(dev,
+				   "%s(): mark %08x -> txq %02x [DISABLE]\n",
+				   __func__, mark, *txq);
+		} else {
+			netdev_dbg(dev, "%s(): No mapping for mark %08x\n",
+				   __func__, mark);
+			break;
+		}
+
+		if (unlikely(*txq >= dev->num_tx_queues))
+			break;
+
+		q = netdev_get_tx_queue(dev, *txq);
+		if (unlikely(!q))
+			break;
+
+		netif_tx_stop_queue(q);
+		break;
+	default:
+		break;
+	}
+}
+
 static void rmnet_unregister_bridge(struct rmnet_port *port)
 {
 	struct net_device *bridge_dev, *real_dev, *rmnet_dev;
@@ -170,6 +255,17 @@ static int rmnet_newlink(struct net *src_net, struct net_device *dev,
 	netdev_dbg(dev, "data format [0x%08X]\n", data_format);
 	port->data_format = data_format;
 
+	if (data[IFLA_RMNET_QUEUE]) {
+		struct rmnet_queue_mapping *queue_map;
+
+		queue_map = nla_data(data[IFLA_RMNET_QUEUE]);
+		netdev_dbg(dev, "%s(): op %02x txq %02x mark %08x\n",
+			   __func__, queue_map->operation, queue_map->txqueue,
+			   queue_map->mark);
+		rmnet_update_queue_map(dev, queue_map->operation,
+				       queue_map->txqueue, queue_map->mark);
+	}
+
 	return 0;
 
 err2:
@@ -347,6 +443,17 @@ static int rmnet_changelink(struct net_device *dev, struct nlattr *tb[],
 		}
 	}
 
+	if (data[IFLA_RMNET_QUEUE]) {
+		struct rmnet_queue_mapping *queue_map;
+
+		queue_map = nla_data(data[IFLA_RMNET_QUEUE]);
+		netdev_dbg(dev, "%s(): op %02x txq %02x mark %08x\n",
+			   __func__, queue_map->operation, queue_map->txqueue,
+			   queue_map->mark);
+		rmnet_update_queue_map(dev, queue_map->operation,
+				       queue_map->txqueue, queue_map->mark);
+	}
+
 	return 0;
 }
 
@@ -356,7 +463,9 @@ static size_t rmnet_get_size(const struct net_device *dev)
 		/* IFLA_RMNET_MUX_ID */
 		nla_total_size(2) +
 		/* IFLA_RMNET_FLAGS */
-		nla_total_size(sizeof(struct ifla_rmnet_flags));
+		nla_total_size(sizeof(struct ifla_rmnet_flags)) +
+		/* IFLA_RMNET_QUEUE */
+		nla_total_size(sizeof(struct rmnet_queue_mapping));
 }
 
 static int rmnet_fill_info(struct sk_buff *skb, const struct net_device *dev)
@@ -391,7 +500,7 @@ static int rmnet_fill_info(struct sk_buff *skb, const struct net_device *dev)
 
 struct rtnl_link_ops rmnet_link_ops __read_mostly = {
 	.kind		= "rmnet",
-	.maxtype	= IFLA_RMNET_MAX,
+	.maxtype	= __IFLA_RMNET_EXT_MAX - 1,
 	.priv_size	= sizeof(struct rmnet_priv),
 	.setup		= rmnet_vnd_setup,
 	.validate	= rmnet_rtnl_validate,
diff --git a/drivers/net/ethernet/qualcomm/rmnet/rmnet_config.h b/drivers/net/ethernet/qualcomm/rmnet/rmnet_config.h
index 3d3cba56c516..e8ed06a3eaca 100644
--- a/drivers/net/ethernet/qualcomm/rmnet/rmnet_config.h
+++ b/drivers/net/ethernet/qualcomm/rmnet/rmnet_config.h
@@ -1,6 +1,7 @@
 /* SPDX-License-Identifier: GPL-2.0-only */
 /* Copyright (c) 2013-2014, 2016-2018, 2021 The Linux Foundation.
  * All rights reserved.
+ * Copyright (c) 2023, Qualcomm Innovation Center, Inc. All rights reserved.
  *
  * RMNET Data configuration engine
  */
@@ -19,6 +20,19 @@ struct rmnet_endpoint {
 	struct hlist_node hlnode;
 };
 
+/* These fields need to go to an UAPI file */
+#define RMNET_QUEUE_MAPPING_ADD 1
+#define RMNET_QUEUE_MAPPING_REMOVE 2
+#define RMNET_QUEUE_ENABLE 3
+#define RMNET_QUEUE_DISABLE 4
+
+struct rmnet_queue_mapping {
+	u8 operation;
+	u8 txqueue;
+	u16 padding;
+	u32 mark;
+};
+
 /* One instance of this structure is instantiated for each real_dev associated
  * with rmnet.
  */
@@ -67,6 +81,7 @@ struct rmnet_priv {
 	struct rmnet_pcpu_stats __percpu *pcpu_stats;
 	struct gro_cells gro_cells;
 	struct rmnet_priv_stats stats;
+	struct xarray queue_map;
 };
 
 struct rmnet_port *rmnet_get_port_rcu(struct net_device *real_dev);
diff --git a/drivers/net/ethernet/qualcomm/rmnet/rmnet_vnd.c b/drivers/net/ethernet/qualcomm/rmnet/rmnet_vnd.c
index 1b2119b1d48a..ce88ca702783 100644
--- a/drivers/net/ethernet/qualcomm/rmnet/rmnet_vnd.c
+++ b/drivers/net/ethernet/qualcomm/rmnet/rmnet_vnd.c
@@ -1,5 +1,6 @@
 // SPDX-License-Identifier: GPL-2.0-only
 /* Copyright (c) 2013-2018, The Linux Foundation. All rights reserved.
+ * Copyright (c) 2023, Qualcomm Innovation Center, Inc. All rights reserved.
  *
  * RMNET Data virtual network driver
  */
@@ -153,6 +154,20 @@ static void rmnet_get_stats64(struct net_device *dev,
 	s->tx_dropped = total_stats.tx_drops;
 }
 
+static u16 rmnet_vnd_select_queue(struct net_device *dev,
+				  struct sk_buff *skb,
+				  struct net_device *sb_dev) {
+	struct rmnet_priv *priv = netdev_priv(dev);
+	int *txq = xa_load(&priv->queue_map, skb->mark);
+
+	if (!txq)
+		return 0;
+
+	netdev_dbg(dev, "%s(): mark %08x -> txq %02x\n", __func__, skb->mark,
+		   *txq);
+	return (*txq < dev->num_tx_queues) ? *txq : 0;
+}
+
 static const struct net_device_ops rmnet_vnd_ops = {
 	.ndo_start_xmit = rmnet_vnd_start_xmit,
 	.ndo_change_mtu = rmnet_vnd_change_mtu,
@@ -162,6 +177,7 @@ static const struct net_device_ops rmnet_vnd_ops = {
 	.ndo_init       = rmnet_vnd_init,
 	.ndo_uninit     = rmnet_vnd_uninit,
 	.ndo_get_stats64 = rmnet_get_stats64,
+	.ndo_select_queue = rmnet_vnd_select_queue,
 };
 
 static const char rmnet_gstrings_stats[][ETH_GSTRING_LEN] = {
@@ -284,6 +300,8 @@ int rmnet_vnd_newlink(u8 id, struct net_device *rmnet_dev,
 
 		priv->mux_id = id;
 
+		xa_init(&priv->queue_map);
+
 		netdev_dbg(rmnet_dev, "rmnet dev created\n");
 	}
 
-- 
2.45.2

